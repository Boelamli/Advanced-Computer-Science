{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#prereq libraries\n",
    "import pandas as pd\n",
    "#for geolocation lat/long\n",
    "#import geopandas as gpd\n",
    "#import geopy\n",
    "#from geopy.geocoders import Nominatim\n",
    "#from geopy.extra.rate_limiter import RateLimiter\n",
    "#import matplotlib.pyplot as plt\n",
    "#import folium\n",
    "#from folium.plugins import FastMarkerCluster\n",
    "#from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read-in csv file and create column headers according to UK housing site\n",
    "df = pd.read_csv(\"pp-complete.csv\", \n",
    "                 sep=',',\n",
    "                 names=[\"Transaction_ID\",\n",
    "                        \"Price\",\n",
    "                        \"Transfer_Date\",\n",
    "                        \"Postcode\",\n",
    "                        \"Property_Type\",\n",
    "                        \"Old_New\",\n",
    "                        \"Duration\",\n",
    "                        \"PAON\",\n",
    "                        \"SAON\",\n",
    "                        \"Street\",\n",
    "                        \"Locality\",\n",
    "                        \"Town_City\",\n",
    "                        \"District\",\n",
    "                        \"County\",\n",
    "                        \"PPD_Category\",\n",
    "                        \"Record Status\",\n",
    "                       ]) #nrows=100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print row length and shape size\n",
    "print(\"data row x columns is {}\\ndata row count is {}\".format(df.shape,len(df.index)))\n",
    "\n",
    "#print first 10 rows as sample\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new concatenated column with selected address info\n",
    "#we will use this column to attempt to call google.maps API using geopy\n",
    "df['Concat_PAON_Street_TownCity_Postcode'] = df['PAON'] + \" \" + df['Street'] + \" \" +  df['Town_City'] + \" \" +  df['Postcode']\n",
    "\n",
    "#print new column with index -first 5 rows only\n",
    "df.iloc[0:5, 16:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "we need to sort the data becuase next we will remove duplicate addresses, keeping the\n",
    "first instance of the address - which after sorting will be the most current address.\n",
    "we will use our newly created concatenated column as unique id.\n",
    "'''\n",
    "#sort date in descending order\n",
    "df = df.sort_values(by='Transfer_Date',ascending=False)\n",
    "\n",
    "#remove duplicate addresses (new concat column) but keep first instance\n",
    "df.drop_duplicates(subset = 'Concat_PAON_Street_TownCity_Postcode', keep = 'first', inplace = True)\n",
    "\n",
    "#print first 10 rows as sample\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "**Get Lat/Long Data with GeoPy**\n",
    "---------------------\n",
    "\n",
    "the code below attempts to call a google.maps API using concat address column as query key and pulls back \n",
    "cooresponding lat/long coordinates.\n",
    "\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds=1)\n",
    "df['location'] = df['ADDRESS'].apply(geocode)\n",
    "df['point'] = df['location'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "**Minimize Dataset to BN Codes Only**\n",
    "---------------------\n",
    "\n",
    "in the case of deleting non-BN codes to make the file smaller, run the script below on df.\n",
    "\n",
    "#string to be searched in start of string\n",
    "search_term = \"BN\"\n",
    "only_brighton_records = df[\"Postcode\"].str.startswith(search_term, na = False)\n",
    "\n",
    "#replace df with only brighton records then print a sample (first head(x))\n",
    "df = df[only_brighton_records]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the contents thus far to new csv file\n",
    "df.to_csv('pp-complete-bn-codes-only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
